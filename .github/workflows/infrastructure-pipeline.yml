name: Infrastructure Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: us-east-1
  TERRAFORM_VERSION: "1.5.0"
  WORKSPACE_DIR: terraform
  MAX_ATTEMPTS: 3
  RETRY_WAIT_SECONDS: 30

jobs:
  full-infra:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Verify working directory"
        run: |
          echo "Current directory: $(pwd)"
          echo "Contents of directory:"
          ls -la
          echo "Changing to terraform directory..."
          cd ${{ env.WORKSPACE_DIR }}
          echo "Contents of terraform directory:"
          ls -la

      - name: "Set up Terraform"
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: "Verify Terraform installation"
        run: |
          terraform version
          echo "Terraform successfully installed"

      - name: "Configure AWS credentials"
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: arn:aws:iam::579177902857:role/actions
          role-duration-seconds: 1200
          role-skip-session-tagging: true

      - name: "Ensure S3 bucket for Terraform state exists"
        run: |
          BUCKET_NAME="epam-final-terraform-state"
          echo "Checking if bucket $BUCKET_NAME exists..."
          if ! aws s3api head-bucket --bucket $BUCKET_NAME 2>/dev/null; then
            echo "Bucket does not exist, creating..."
            aws s3api create-bucket --bucket $BUCKET_NAME --region ${{ env.AWS_REGION }}
            aws s3api put-bucket-versioning --bucket $BUCKET_NAME --versioning-configuration Status=Enabled
            echo "Bucket created and versioning enabled"
          else
            echo "Bucket already exists, skipping creation"
          fi

      - name: "Ensure DynamoDB table for Terraform lock exists"
        run: |
          TABLE_NAME="epam-final-terraform-locks"
          echo "Checking if DynamoDB table $TABLE_NAME exists..."
          if ! aws dynamodb describe-table --table-name $TABLE_NAME --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "Table does not exist, creating..."
            aws dynamodb create-table \
              --table-name $TABLE_NAME \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region ${{ env.AWS_REGION }}
            echo "Table created successfully"
          else
            echo "Table already exists, skipping creation"
          fi

      - name: "Terraform Init"
        run: |
          cd ${{ env.WORKSPACE_DIR }}
          echo "Initializing Terraform..."
          terraform init
          echo "Terraform initialized successfully"

      - name: "Remove Orphaned Kubernetes Resources from State"
        run: |
          cd ${{ env.WORKSPACE_DIR }}
          echo "Attempting to remove orphaned Kubernetes ConfigMap from Terraform state..."
          # This command removes the resource from the state file.
          # We add "|| true" so the pipeline doesn't fail if the resource is already gone.
          terraform state rm -lock=false kubernetes_config_map_v1_data.aws_auth || true

      - name: "Create terraform.tfvars"
        run: |
          echo "Creating terraform.tfvars file..."
          cat > ${{ env.WORKSPACE_DIR }}/terraform.tfvars <<EOF
          api_key    = "${{ secrets.API_KEY }}"
          aws_region = "${{ env.AWS_REGION }}"
          github_pat = "${{ secrets.GH_PAT }}"
          EOF
          echo "terraform.tfvars created successfully"

      - name: "Terraform Plan"
        run: |
          cd ${{ env.WORKSPACE_DIR }}
          echo "Running Terraform plan..."
          terraform plan -lock=false -out=tfplan
          echo "Terraform plan completed successfully"

      - name: "Terraform Apply with Retry"
        run: |
          for i in $(seq 1 ${{ env.MAX_ATTEMPTS }}); do
            echo "Attempt $i of ${{ env.MAX_ATTEMPTS }}"
            if cd ${{ env.WORKSPACE_DIR }} && terraform apply -auto-approve -lock=false tfplan; then
              echo "Terraform apply succeeded"
              break
            else
              if [ $i -eq ${{ env.MAX_ATTEMPTS }} ]; then
                echo "Failed after ${{ env.MAX_ATTEMPTS }} attempts"
                exit 1
              fi
              echo "Waiting ${{ env.RETRY_WAIT_SECONDS }} seconds before retry..."
              sleep ${{ env.RETRY_WAIT_SECONDS }}
            fi
          done

      - name: "Save EKS Node Role ARN"
        id: save_output
        run: |
          cd ${{ env.WORKSPACE_DIR }}
          echo "Saving EKS node role ARN to file..."
          terraform output -raw eks_node_role_arn > eks_node_role_arn.txt
          cat eks_node_role_arn.txt

      - name: "Upload EKS Node Role ARN Artifact"
        uses: actions/upload-artifact@v4
        with:
          name: eks-node-role-arn
          path: ${{ env.WORKSPACE_DIR }}/eks_node_role_arn.txt

      - name: "Verify EKS Cluster with Retry"
        run: |
          # This step will only succeed if the runner is inside the VPC
          for i in $(seq 1 ${{ env.MAX_ATTEMPTS }}); do
            echo "Attempt $i of ${{ env.MAX_ATTEMPTS }}"
            if CLUSTER_NAME=$(cd ${{ env.WORKSPACE_DIR }} && terraform output -raw cluster_name) && \
               aws eks describe-cluster --name $CLUSTER_NAME --region ${{ env.AWS_REGION }} && \
               aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }} && \
               kubectl get nodes; then
              echo "EKS cluster verification succeeded"
              break
            else
              if [ $i -eq ${{ env.MAX_ATTEMPTS }} ]; then
                echo "Failed after ${{ env.MAX_ATTEMPTS }} attempts"
                exit 1
              fi
              echo "Waiting ${{ env.RETRY_WAIT_SECONDS }} seconds before retry..."
              sleep ${{ env.RETRY_WAIT_SECONDS }}
            fi
          done

      - name: "Delete terraform.tfvars"
        if: always()
        run: |
          echo "Cleaning up terraform.tfvars..."
          rm -f ${{ env.WORKSPACE_DIR }}/terraform.tfvars
          echo "Cleanup completed"
